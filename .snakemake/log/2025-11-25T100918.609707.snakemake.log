Assuming unrestricted shared filesystem usage.
None
host: arash-XPS-13-9310
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job      count
-----  -------
all          1
fetch        1
merge        1
total        3

Select jobs to execute...
Execute 1 jobs...
[Tue Nov 25 10:09:18 2025]
localrule fetch:
    input: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/srcbib
    output: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/logs/fetched_pdfs.txt
    jobid: 2
    reason: Missing output files: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/logs/fetched_pdfs.txt; Code has changed since last execution
    resources: tmpdir=/tmp
Shell command: python -m bib.fetch
RuleException:
CalledProcessError in file "/home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/Snakefile", line 55:
Command 'set -euo pipefail;  python -m bib.fetch' returned non-zero exit status 1.
[Tue Nov 25 10:09:18 2025]
Error in rule fetch:
    message: None
    jobid: 2
    input: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/srcbib
    output: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/logs/fetched_pdfs.txt
    shell:
        python -m bib.fetch
        (command exited with non-zero exit code)
Shutting down, this might take some time.
Exiting because a job execution failed. Look below for error messages
[Tue Nov 25 10:09:18 2025]
Error in rule fetch:
    message: None
    jobid: 2
    input: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/srcbib
    output: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/logs/fetched_pdfs.txt
    shell:
        python -m bib.fetch
        (command exited with non-zero exit code)
Complete log(s): /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/.snakemake/log/2025-11-25T100918.609707.snakemake.log
WorkflowError:
At least one job did not complete successfully.

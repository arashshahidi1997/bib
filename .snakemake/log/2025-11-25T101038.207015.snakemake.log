Assuming unrestricted shared filesystem usage.
None
host: arash-XPS-13-9310
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job      count
-----  -------
all          1
merge        1
total        2

Select jobs to execute...
Execute 1 jobs...
[Tue Nov 25 10:10:38 2025]
localrule merge:
    input: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/logs/fetched_pdfs.txt
    output: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/neuropy.bib
    jobid: 1
    reason: Missing output files: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/neuropy.bib
    resources: tmpdir=/tmp
Shell command: python -m bib.merge
RuleException:
CalledProcessError in file "/home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/Snakefile", line 63:
Command 'set -euo pipefail;  python -m bib.merge' returned non-zero exit status 1.
[Tue Nov 25 10:10:38 2025]
Error in rule merge:
    message: None
    jobid: 1
    input: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/logs/fetched_pdfs.txt
    output: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/neuropy.bib
    shell:
        python -m bib.merge
        (command exited with non-zero exit code)
Shutting down, this might take some time.
Exiting because a job execution failed. Look below for error messages
[Tue Nov 25 10:10:38 2025]
Error in rule merge:
    message: None
    jobid: 1
    input: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/logs/fetched_pdfs.txt
    output: /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/neuropy.bib
    shell:
        python -m bib.merge
        (command exited with non-zero exit code)
Complete log(s): /home/arash/Documents/Science/Uni/NeuroPy/NeuroPySeminar/bib/.snakemake/log/2025-11-25T101038.207015.snakemake.log
WorkflowError:
At least one job did not complete successfully.
